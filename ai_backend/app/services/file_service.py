"""
File Service

Supabase Storageì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì™€ ì „ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ì„œë¹„ìŠ¤
"""
import os
import tempfile
import httpx
from typing import Optional
from datetime import datetime
import logging

from ..core.supabase import get_supabase_client
from .file_processors.processor_factory import FileProcessorFactory
from .file_processors.base_processor import ProcessedFile

logger = logging.getLogger(__name__)


def sanitize_text(text: Optional[str]) -> Optional[str]:
    """
    PostgreSQL TEXT íƒ€ì…ì— ì €ì¥í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        ì •ì œëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return text

    # NULL ë°”ì´íŠ¸ ì œê±° (PostgreSQL TEXT íƒ€ì…ì€ \u0000ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ)
    text = text.replace('\u0000', '')

    # ê¸°íƒ€ ì œì–´ ë¬¸ì ì œê±° (ì„ íƒì )
    # text = ''.join(char for char in text if char.isprintable() or char in '\n\r\t')

    return text


class FileService:
    """
    íŒŒì¼ ì²˜ë¦¬ ì„œë¹„ìŠ¤

    1. ai_conversation_files í…Œì´ë¸”ì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ
    2. Supabase Storageì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    3. ì ì ˆí•œ í”„ë¡œì„¸ì„œë¡œ ì „ì²˜ë¦¬
    4. ai_preprocessed_data í…Œì´ë¸”ì— ê²°ê³¼ ì €ì¥
    """

    def __init__(self):
        self.supabase = get_supabase_client()

    async def process_file_from_storage(
        self,
        file_id: str
    ) -> ProcessedFile:
        """
        Supabase Storageì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì™€ ì²˜ë¦¬

        Args:
            file_id: ai_conversation_files í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ID

        Returns:
            ProcessedFile: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            logger.info(f"ğŸ”„ Processing file from storage: {file_id}")

            # 1. ai_conversation_files í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
            file_record = self.supabase.table('ai_conversation_files') \
                .select('*') \
                .eq('id', file_id) \
                .single() \
                .execute()

            if not file_record.data:
                raise ValueError(f"File record not found: {file_id}")

            file_data = file_record.data
            file_url = file_data['file_url']
            file_name = file_data.get('original_file_name') or file_data['file_name']
            couple_id = file_data.get('couple_id')
            user_id = file_data.get('user_id')

            logger.info(f"   File: {file_name}")
            logger.info(f"   URL: {file_url}")

            # 2. statusë¥¼ 'processing'ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            self.supabase.table('ai_conversation_files') \
                .update({'status': 'processing'}) \
                .eq('id', file_id) \
                .execute()

            # 3. íŒŒì¼ ë‹¤ìš´ë¡œë“œ (file_urlì—ì„œ ì§ì ‘)
            local_path = await self._download_from_url(file_url, file_name)

            # 4. ì ì ˆí•œ í”„ë¡œì„¸ì„œë¡œ ì²˜ë¦¬
            processor = FileProcessorFactory.get_processor(file_name)

            if not processor:
                raise ValueError(
                    f"No processor found for file: {file_name}. "
                    f"Supported extensions: {FileProcessorFactory.get_supported_extensions()}"
                )

            result = await processor.process(local_path)

            # 5. ì²˜ë¦¬ ê²°ê³¼ë¥¼ ai_preprocessed_data í…Œì´ë¸”ì— ì €ì¥
            await self._save_to_preprocessed_data(
                file_id=file_id,
                couple_id=couple_id,
                user_id=user_id,
                result=result
            )

            # 6. ai_conversation_files statusë¥¼ 'completed'ë¡œ ì—…ë°ì´íŠ¸
            self.supabase.table('ai_conversation_files') \
                .update({'status': 'completed'}) \
                .eq('id', file_id) \
                .execute()

            # 7. ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(local_path):
                os.remove(local_path)
                logger.debug(f"ğŸ—‘ï¸ Deleted temp file: {local_path}")

            logger.info(f"âœ… File processing completed: {file_id}")
            return result

        except Exception as e:
            logger.error(f"âŒ File processing failed: {e}", exc_info=True)

            # ì‹¤íŒ¨ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
            try:
                self.supabase.table('ai_conversation_files') \
                    .update({'status': 'failed'}) \
                    .eq('id', file_id) \
                    .execute()
            except:
                pass

            raise

    async def _download_from_url(
        self,
        file_url: str,
        file_name: str
    ) -> str:
        """
        URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ

        Args:
            file_url: íŒŒì¼ URL (Supabase Storage public URL)
            file_name: íŒŒì¼ ì´ë¦„

        Returns:
            str: ë¡œì»¬ ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        """
        try:
            logger.info(f"â¬‡ï¸ Downloading from URL: {file_url[:50]}...")

            # HTTP GETìœ¼ë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.get(file_url)
                response.raise_for_status()

            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_dir = tempfile.mkdtemp()
            local_path = os.path.join(temp_dir, file_name)

            with open(local_path, 'wb') as f:
                f.write(response.content)

            logger.info(f"âœ… Downloaded to: {local_path}")
            return local_path

        except Exception as e:
            logger.error(f"Download failed: {e}")
            raise

    async def _save_to_preprocessed_data(
        self,
        file_id: str,
        couple_id: Optional[str],
        user_id: Optional[str],
        result: ProcessedFile
    ):
        """
        ì²˜ë¦¬ ê²°ê³¼ë¥¼ ai_preprocessed_data í…Œì´ë¸”ì— ì €ì¥

        Args:
            file_id: íŒŒì¼ ID
            couple_id: ì»¤í”Œ ID
            user_id: ì‚¬ìš©ì ID
            result: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            # ëŒ€í™” ë°ì´í„°ë¥¼ JSONB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í…ìŠ¤íŠ¸ ì •ì œ)
            parsed_conversations = []
            if result.conversations:
                for msg in result.conversations:
                    parsed_conversations.append({
                        'timestamp': msg.timestamp.isoformat() if msg.timestamp else None,
                        'sender': sanitize_text(msg.sender),
                        'message': sanitize_text(msg.message),
                        'metadata': msg.metadata
                    })

            # ai_preprocessed_dataì— INSERT
            # NOTE: user_idëŠ” profiles í…Œì´ë¸”ì— ë ˆì½”ë“œê°€ ìˆì–´ì•¼ í•¨
            # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¼ë‹¨ None ì„¤ì • (ì‹¤ì œ ì•± ì‚¬ìš© ì‹œ ìë™ ìƒì„±ë¨)
            preprocessed_data = {
                'file_id': file_id,
                'couple_id': couple_id,
                'user_id': None,  # profilesì— ë ˆì½”ë“œ ì—†ìœ¼ë©´ FK ì—ëŸ¬ ë°œìƒí•˜ë¯€ë¡œ None
                'processing_status': 'completed' if result.success else 'failed',
                'extracted_text': sanitize_text(result.raw_text),
                'parsed_conversations': parsed_conversations,
                'total_messages': result.total_messages,
                'participants': result.participants,
                'date_range': {
                    'start': result.date_range['start'].isoformat() if result.date_range and result.date_range.get('start') else None,
                    'end': result.date_range['end'].isoformat() if result.date_range and result.date_range.get('end') else None,
                } if result.date_range else None,
                'file_type': result.file_type,
                'error_message': result.error_message if not result.success else None,
                'warnings': result.warnings,
                'processed_at': datetime.now().isoformat()
            }

            insert_result = self.supabase.table('ai_preprocessed_data') \
                .insert(preprocessed_data) \
                .execute()

            logger.info(f"ğŸ’¾ Saved preprocessing result to ai_preprocessed_data")

            if insert_result.data:
                preprocessed_id = insert_result.data[0]['id']
                logger.info(f"   Preprocessed data ID: {preprocessed_id}")

        except Exception as e:
            logger.error(f"Failed to save preprocessing result: {e}")
            raise


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_file_service_instance = None


def get_file_service() -> FileService:
    """File Service ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _file_service_instance
    if _file_service_instance is None:
        _file_service_instance = FileService()
    return _file_service_instance
