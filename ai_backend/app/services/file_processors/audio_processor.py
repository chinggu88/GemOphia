"""
ì˜¤ë””ì˜¤ íŒŒì¼ í”„ë¡œì„¸ì„œ

STT (Speech-to-Text)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
"""
from typing import List
from datetime import datetime
import logging

from .base_processor import BaseFileProcessor, ProcessedFile, ConversationMessage

logger = logging.getLogger(__name__)


class AudioProcessor(BaseFileProcessor):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ í”„ë¡œì„¸ì„œ

    Whisper ë˜ëŠ” Google STTë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜
    """

    @property
    def supported_extensions(self) -> List[str]:
        return ['.mp3', '.wav', '.m4a', '.ogg', '.flac']

    @property
    def processor_name(self) -> str:
        return 'AudioProcessor'

    async def process(self, file_path: str, **kwargs) -> ProcessedFile:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (STT)

        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            **kwargs:
                - stt_provider: 'whisper' (ê¸°ë³¸ê°’) ë˜ëŠ” 'google'
                - language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: 'ko')
                - model_size: Whisper ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large)

        Returns:
            ProcessedFile: ì²˜ë¦¬ ê²°ê³¼
        """
        stt_provider = kwargs.get('stt_provider', 'whisper')
        language = kwargs.get('language', 'ko')

        try:
            logger.info(f"ğŸ¤ Processing audio file: {file_path}")
            logger.info(f"   STT Provider: {stt_provider}")

            # STT ì‹¤í–‰
            if stt_provider == 'whisper':
                transcribed_text = await self._transcribe_with_whisper(
                    file_path,
                    language=language,
                    model_size=kwargs.get('model_size', 'base')
                )
            elif stt_provider == 'google':
                transcribed_text = await self._transcribe_with_google(
                    file_path,
                    language=language
                )
            else:
                raise ValueError(f"Unsupported STT provider: {stt_provider}")

            if not transcribed_text:
                logger.warning("No text transcribed from audio")
                return ProcessedFile(
                    success=False,
                    file_type='audio',
                    error_message="ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                )

            logger.info(f"âœ… Transcribed {len(transcribed_text)} characters")

            # ìŒì„± íŒŒì¼ì€ ë‹¨ì¼ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬ (í™”ì ë¶„ë¦¬ ì—†ì´)
            # TODO: í™”ì ë¶„ë¦¬ (Speaker Diarization) ì¶”ê°€ ê³ ë ¤
            conversations = [ConversationMessage(
                timestamp=datetime.now(),  # TODO: íŒŒì¼ ìƒì„± ì‹œê°„ ì‚¬ìš©
                sender="Unknown",  # TODO: í™”ì ë¶„ë¦¬ í›„ ì‹ë³„
                message=transcribed_text,
                metadata={
                    'stt_provider': stt_provider,
                    'language': language,
                    'original_file': file_path
                }
            )]

            return ProcessedFile(
                success=True,
                file_type='audio',
                raw_text=transcribed_text,
                conversations=conversations,
                total_messages=1,
                warnings=["í™”ì ë¶„ë¦¬ê°€ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ì²´ ë‚´ìš©ì´ ë‹¨ì¼ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤."]
            )

        except Exception as e:
            logger.error(f"âŒ Error processing audio file: {e}", exc_info=True)
            return ProcessedFile(
                success=False,
                file_type='audio',
                error_message=str(e)
            )

    async def _transcribe_with_whisper(
        self,
        file_path: str,
        language: str = 'ko',
        model_size: str = 'base'
    ) -> str:
        """
        Whisperë¥¼ ì‚¬ìš©í•œ STT

        Args:
            file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
            model_size: ëª¨ë¸ í¬ê¸° (tiny, base, small, medium, large)

        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        try:
            import whisper

            logger.info(f"ğŸ¤– Loading Whisper model: {model_size}")
            model = whisper.load_model(model_size)

            logger.info(f"ğŸ™ï¸ Transcribing audio...")
            result = model.transcribe(
                file_path,
                language=language,
                verbose=False
            )

            return result['text']

        except ImportError:
            logger.error("Whisper not installed. Run: pip install openai-whisper")
            raise ImportError(
                "Whisper is required for audio processing. "
                "Install it with: pip install openai-whisper"
            )
        except Exception as e:
            logger.error(f"Whisper transcription failed: {e}")
            raise

    async def _transcribe_with_google(self, file_path: str, language: str = 'ko') -> str:
        """
        Google Speech-to-Text API ì‚¬ìš©

        Args:
            file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (ko-KR, en-US ë“±)

        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        # TODO: Google STT API êµ¬í˜„
        raise NotImplementedError("Google STT is not implemented yet")
