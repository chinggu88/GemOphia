"""
Supabase Realtime Listener

ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ DBì— ë“¤ì–´ì˜¤ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

Phase 1: ê¸°ë³¸ ë¦¬ìŠ¤ë„ˆ + ê°„ë‹¨í•œ ê°ì • ë¶„ì„
Phase 2: STT, NER, Auto-Scheduler ì¶”ê°€ ì˜ˆì •
"""
import asyncio
from typing import Dict, Any
import logging
from datetime import datetime

from ..core.supabase import get_supabase_client
from .emotion_analyzer import analyze_text_emotion
from ..services.ner_service import NERService
from ..services.schedule_service import ScheduleService

logger = logging.getLogger(__name__)


class RealtimeMessageListener:
    """
    Supabase Realtimeì„ ì‚¬ìš©í•´ì„œ messages í…Œì´ë¸”ì„ êµ¬ë…í•˜ê³ 
    ìƒˆ ë©”ì‹œì§€ê°€ ë“¤ì–´ì˜¤ë©´ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self.supabase = get_supabase_client()
        self.ner_service = NERService()
        self.schedule_service = ScheduleService()
        logger.info("âœ… RealtimeMessageListener initialized")
        self.channel = None

    async def handle_new_message(self, payload: Dict[str, Any]):
        """
        ìƒˆ ë©”ì‹œì§€ê°€ INSERTë˜ë©´ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜

        Args:
            payload: Supabase Realtime ì´ë²¤íŠ¸ í˜ì´ë¡œë“œ
                {
                    'type': 'INSERT',
                    'record': {
                        'id': 'uuid',
                        'couple_id': 'uuid',
                        'sender_id': 'uuid',
                        'content': 'ë©”ì‹œì§€ ë‚´ìš©',
                        'message_type': 'text',
                        'created_at': '2025-01-16T...'
                    },
                    'old_record': None
                }
        """
        try:
            # 1. ë©”ì‹œì§€ ë°ì´í„° ì¶”ì¶œ
            event_type = payload.get('type')
            message = payload.get('record', {})

            if event_type != 'INSERT':
                logger.info(f"Skipping non-INSERT event: {event_type}")
                return

            conversation_id = message.get('id')
            content = message.get('content')
            conversation_type = message.get('conversation_type', 'daily')
            couple_id = message.get('couple_id')
            user_id = message.get('user_id')

            if not conversation_id or not content:
                logger.warning(f"Invalid conversation payload: {payload}")
                return

            logger.info(
                f"ğŸ”” New conversation received!\n"
                f"   ID: {conversation_id[:8]}...\n"
                f"   Couple: {couple_id[:8] if couple_id else 'unknown'}...\n"
                f"   User: {user_id[:8] if user_id else 'unknown'}...\n"
                f"   Type: {conversation_type}\n"
                f"   Content: {content[:50]}..."
            )

            # ============================================================
            # Phase 1: ê°„ë‹¨í•œ ê°ì • ë¶„ì„ë§Œ ì‹¤í–‰
            # ============================================================

            # TODO Phase 2: STT ì²˜ë¦¬ (message_type == 'voice'ì¼ ë•Œ)
            # if message_type == 'voice':
            #     content = await stt_service.transcribe(content)

            # TODO Phase 2: NER ì²˜ë¦¬ (ë‚ ì§œ, ì¥ì†Œ, í™œë™ ì¶”ì¶œ)
            # ner_results = await ner_service.extract(content)

            # TODO Phase 2: ìë™ ì¼ì • ìƒì„±
            # if ner_results:
            #     await auto_scheduler.create_schedule(ner_results)

            # 2. ê°ì • ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ ì½”ë“œ í™œìš©)
            logger.info(f"ğŸ¤– Analyzing emotion for conversation {conversation_id[:8]}...")
            emotion_result = await analyze_text_emotion(content)

            logger.info(
                f"âœ… Analysis complete!\n"
                f"   Emotion: {emotion_result.emotion}\n"
                f"   Confidence: {emotion_result.confidence:.2f}\n"
                f"   Scores: {emotion_result.all_scores}"
            )

            # 3. ë¶„ì„ ê²°ê³¼ë¥¼ conversations í…Œì´ë¸”ì— ì—…ë°ì´íŠ¸
            # sentimentì™€ emotion_score ì»¬ëŸ¼ í™œìš©
            update_data = {
                'sentiment': emotion_result.emotion,  # positive/negative/neutral
                'emotion_score': int(emotion_result.confidence * 100)  # 0-100
            }

            self.supabase.table('conversations').update(update_data).eq('id', conversation_id).execute()

            logger.info(
                f"ğŸ’¾ Emotion analysis saved to conversations table!\n"
                f"   Conversation ID: {conversation_id[:8]}...\n"
                f"   Sentiment: {update_data['sentiment']}\n"
                f"   Score: {update_data['emotion_score']}"
            )

            # 4. analysis_results í…Œì´ë¸”ì— ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥
            analysis_data = {
                'conversation_id': conversation_id,
                'emotion': emotion_result.emotion,
                'confidence': float(emotion_result.confidence),
                'all_scores': emotion_result.all_scores,
                'voice_emotion': getattr(emotion_result, 'voice_emotion', None),
                'topics': [],  # TODO: Phase 3ì—ì„œ ì£¼ì œ ì¶”ì¶œ ê¸°ëŠ¥ ì¶”ê°€
                'keywords': [],  # TODO: Phase 1.5ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥ ì¶”ê°€
                'processed_at': datetime.now().isoformat()
            }
            
            try:
                self.supabase.table('analysis_results').insert(analysis_data).execute()
                logger.info(f"ğŸ’¾ Detailed analysis saved to analysis_results table for {conversation_id[:8]}")
            except Exception as db_error:
                logger.error(f"âš ï¸ Failed to save analysis_results: {db_error}")

            # 5. NER ë° ì¼ì • ì¶”ì¶œ (Phase 3)
            try:
                entities = await self.ner_service.extract_entities(content)
                if entities:
                    logger.info(f"ğŸ” Found {len(entities)} entities in message")
                    
                    # ner_extractions ì €ì¥
                    ner_data = [
                        {
                            'conversation_id': conversation_id,
                            'entity_type': e.type,
                            'entity_value': e.value,
                            'confidence': float(e.confidence),
                            'extracted_at': datetime.now().isoformat()
                        }
                        for e in entities
                    ]
                    self.supabase.table('ner_extractions').insert(ner_data).execute()
                    
                    # ì¼ì • ìë™ ìƒì„± ë¡œì§
                    # couple_idê°€ í•„ìš”í•¨. conversation_idë¡œ couple_idë¥¼ ì¡°íšŒí•´ì•¼ í•˜ì§€ë§Œ, 
                    # ì„±ëŠ¥ì„ ìœ„í•´ ë©”ì‹œì§€ í˜ì´ë¡œë“œë‚˜ ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì¢‹ìŒ.
                    # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ DBì—ì„œ ì¡°íšŒí•œë‹¤ê³  ê°€ì • (ë˜ëŠ” payloadì— ìˆë‹¤ê³  ê°€ì •)
                    # payloadì— couple_idê°€ ì—†ë‹¤ë©´ conversation ì¡°íšŒ í•„ìš”
                    
                    # ì„ì‹œ: conversation_idë¡œ couple_id ì¡°íšŒ
                    conv_res = self.supabase.table('conversations').select('couple_id').eq('id', conversation_id).single().execute()
                    if conv_res.data:
                        couple_id = conv_res.data['couple_id']
                        await self.schedule_service.create_pending_schedule(couple_id, entities, content)
                    
            except Exception as ner_error:
                logger.error(f"âš ï¸ NER extraction failed: {ner_error}")

            # TODO Phase 2: ì¶”ê°€ íŒŒì´í”„ë¼ì¸
            # - conversation_summaries (ì¼ë³„ ìš”ì•½)
            # - topic_history ì—…ë°ì´íŠ¸
            # - user_preferences í•™ìŠµ

        except Exception as e:
            logger.error(
                f"âŒ Error handling new conversation:\n"
                f"   Conversation ID: {message.get('id', 'unknown')}\n"
                f"   Error: {e}",
                exc_info=True
            )

    def start(self):
        """
        Realtime êµ¬ë… ì‹œì‘

        messages í…Œì´ë¸”ì˜ INSERT ì´ë²¤íŠ¸ë¥¼ êµ¬ë…í•©ë‹ˆë‹¤.
        """
        try:
            logger.info("ğŸš€ Starting Supabase Realtime listener...")

            # Realtime ì±„ë„ ìƒì„±
            self.channel = self.supabase.channel('messages-listener')

            # conversations í…Œì´ë¸”ì˜ INSERT ì´ë²¤íŠ¸ êµ¬ë…
            self.channel.on_postgres_changes(
                event='INSERT',          # INSERT ì´ë²¤íŠ¸ë§Œ ê°ì§€
                schema='public',         # public ìŠ¤í‚¤ë§ˆ
                table='conversations',   # conversations í…Œì´ë¸” (ì‹¤ì œ DB í…Œì´ë¸”ëª…)
                callback=lambda payload: asyncio.create_task(
                    self.handle_new_message(payload)
                )
            ).subscribe()

            logger.info(
                "âœ… Realtime listener started successfully!\n"
                "   Listening for new messages in 'conversations' table...\n"
                "   Press Ctrl+C to stop."
            )

        except Exception as e:
            logger.error(f"âŒ Failed to start Realtime listener: {e}", exc_info=True)
            raise

    def stop(self):
        """
        Realtime êµ¬ë… ì¤‘ì§€
        """
        if self.channel:
            try:
                self.supabase.remove_channel(self.channel)
                logger.info("ğŸ›‘ Realtime listener stopped")
            except Exception as e:
                logger.error(f"Error stopping listener: {e}")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_listener_instance = None


def get_listener() -> RealtimeMessageListener:
    """Realtime ë¦¬ìŠ¤ë„ˆ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _listener_instance
    if _listener_instance is None:
        _listener_instance = RealtimeMessageListener()
    return _listener_instance
